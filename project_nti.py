# -*- coding: utf-8 -*-
"""PROJECT NTI.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1TUs-S9iqbRZ9w1ZbfuhLn15eLfSRLl_S
"""

from google.colab import drive
drive.mount('/content/drive')

"""# Data Preparation and Preprocessing

"""

#reading data
import os
import cv2
import numpy as np
import matplotlib.pyplot as plt


genuine_path = "/content/drive/MyDrive/signature/full_org"
forged_path = "/content/drive/MyDrive/signature/full_forg"

# load images
def load_images_from_folder(folder, label):
    images = []
    labels = []
    for filename in os.listdir(folder):
        img_path = os.path.join(folder, filename)
        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)
        if img is not None:
            images.append(img)
            labels.append(label)
    return images, labels

genuine_images, genuine_labels = load_images_from_folder(genuine_path, 1)
forged_images, forged_labels = load_images_from_folder(forged_path, 0)


all_images = genuine_images + forged_images
all_labels = genuine_labels + forged_labels

#if 1 means genuie
print("First 5 labels:", all_labels[:5])

#if 0 means forged
print("Last 5 labels:", all_labels[-5:])

print("Genuine:", len(genuine_images))
print("Forged:", len(forged_images))

def resize_images(images, size=(128, 128)):
    resized = []
    for img in images:
        resized.append(cv2.resize(img, size))
    return np.array(resized)

resized_images = resize_images(all_images)

#resize all images to the same size
#CNN require fixed input shape

def binarize_images(images):
    binarized = []
    for img in images:
        _, thresh_img = cv2.threshold(img, 127, 255, cv2.THRESH_BINARY_INV)
        binarized.append(thresh_img)
    return np.array(binarized)

binarized_images = binarize_images(resized_images)

#apply binary thersholding
#convert grayscale image to black& white to highlight the signature

def remove_noise(images):
    denoised = []
    for img in images:
        blur = cv2.GaussianBlur(img, (3, 3), 0)
        denoised.append(blur)
    return np.array(denoised)

clean_images = remove_noise(binarized_images)
#remove noise using guassinblur
#helps in removing small dots and noise around the signature

#normalize pixel to [0,1]
#helps models train faster
X = clean_images / 255.0
X = X.reshape(-1, 128, 128, 1)  # CNN input shape
y = np.array(all_labels)

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
#split the data to trainig and testing[80,20]

from tensorflow.keras.preprocessing.image import ImageDataGenerator

# Augmentation مخفف ومحسّن
datagen = ImageDataGenerator(
    rotation_range=10,
    width_shift_range=0.05,
    height_shift_range=0.05,
    zoom_range=0.05
)
datagen.fit(X_train)

# from tensorflow.keras.preprocessing.image import ImageDataGenerator

# datagen = ImageDataGenerator(
#     rotation_range=10,
#     width_shift_range=0.1,
#     height_shift_range=0.1,
#     zoom_range=0.1
# )
# datagen.fit(X_train)
# #agumentation to increase the data to make the learning more

from collections import Counter
import os

folder_path = "/content/drive/MyDrive/signature"
labels = [folder.split("_")[0] for folder in os.listdir(folder_path)]
print(Counter(labels))

import seaborn as sns
import pandas as pd

df = pd.DataFrame({"Label": ["Genuine" if l == 1 else "Forged" for l in all_labels]})
sns.countplot(data=df, x="Label")
plt.title("Number of Genuine vs Forged Signatures")
plt.show()

import matplotlib.pyplot as plt

def show_samples(images, labels, n=6):
    plt.figure(figsize=(12, 4))
    for i in range(n):
        plt.subplot(1, n, i+1)
        plt.imshow(images[i], cmap='gray')
        plt.title("Genuine" if labels[i] == 1 else "Forged")
        plt.axis('off')
    plt.tight_layout()
    plt.show()

show_samples(all_images, all_labels)

# Assuming the first part of resized_images are genuine and the latter part are forged
# We need to find the index where the genuine images end and forged images begin
# Based on the creation of all_images = genuine_images + forged_images
# The number of genuine images is len(genuine_images)
genuine_count = len(genuine_images)

# Select the first genuine image and the first forged image from resized_images
# Ensure there is at least one genuine and one forged image available
if genuine_count > 0 and len(resized_images) > genuine_count:
    overlay = cv2.addWeighted(resized_images[0], 0.5, resized_images[genuine_count], 0.5, 0)
    plt.imshow(overlay, cmap='gray')
    plt.title("Overlay: Genuine vs Forged (Resized Images)")
    plt.axis('off')
    plt.show()
else:
    print("Not enough genuine and forged images available to create overlay.")

fig, axs = plt.subplots(1, 4, figsize=(16, 4))

axs[0].imshow(all_images[0], cmap='gray')
axs[0].set_title("Original")

axs[1].imshow(resized_images[0], cmap='gray')
axs[1].set_title("Resized")

axs[2].imshow(binarized_images[0], cmap='gray')
axs[2].set_title("Binarized")

axs[3].imshow(clean_images[0], cmap='gray')
axs[3].set_title("Denoised")

for ax in axs:
    ax.axis('off')

plt.tight_layout()
plt.show()

intensities = [np.mean(img) for img in clean_images]
plt.hist(intensities, bins=30)
plt.title("Mean Pixel Intensity Distribution")
plt.xlabel("Intensity")
plt.ylabel("Frequency")
plt.show()

plt.hist(all_images[0].ravel(), bins=256, range=[0, 256])
plt.title("Pixel Histogram - Original")
plt.xlabel("Pixel Value")
plt.ylabel("Frequency")
plt.show()

"""## Model"""

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, Activation
from tensorflow.keras.callbacks import EarlyStopping
from tensorflow.keras.optimizers import Adam


model = Sequential()
model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 1)))
model.add(MaxPooling2D((2, 2)))

model.add(Conv2D(64, (3, 3), activation='relu'))
model.add(MaxPooling2D((2, 2)))

model.add(Flatten())
model.add(Dense(64, activation='relu'))
model.add(Dropout(0.3))
model.add(Dense(1, activation='sigmoid'))

model.compile(optimizer=Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])
model.summary()

early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)


history = model.fit(
    datagen.flow(X_train, y_train, batch_size=32),
    epochs=20 ,
    validation_data=(X_test, y_test),
    callbacks=[early_stop]
)

train_loss, train_acc = model.evaluate(X_train, y_train, verbose=0)
print(f"Train Accuracy: {train_acc * 100:.2f}%")


test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)
print(f" Test Accuracy: {test_acc * 100:.2f}%")

import matplotlib.pyplot as plt


plt.figure(figsize=(12, 5))

# Accuracy plot
plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='Train Accuracy', marker='o')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy', marker='o')
plt.title('Accuracy vs. Epochs')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.grid(True)

# Loss plot
plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], label='Train Loss', marker='o')
plt.plot(history.history['val_loss'], label='Validation Loss', marker='o')
plt.title('Loss vs. Epochs')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.grid(True)

plt.tight_layout()
plt.show()

from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay


y_pred = model.predict(X_test)
y_pred_labels = (y_pred > 0.5).astype(int).flatten()


print(classification_report(y_test, y_pred_labels, target_names=["Forged", "Genuine"]))

# cnfusion Matrix
cm = confusion_matrix(y_test, y_pred_labels)
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=["Forged", "Genuine"])
disp.plot(cmap=plt.cm.Blues)
plt.title("Confusion Matrix")
plt.show()

def test_predictions(indexes):
    plt.figure(figsize=(12, 4))
    for i, idx in enumerate(indexes):
        plt.subplot(1, len(indexes), i+1)
        plt.imshow(X_test[idx].reshape(128, 128), cmap='gray')
        pred_label = "Genuine" if y_pred_labels[idx] == 1 else "Forged"
        true_label = "Genuine" if y_test[idx] == 1 else "Forged"
        color = 'green' if pred_label == true_label else 'red'
        plt.title(f"Pred: {pred_label}\nTrue: {true_label}", color=color)
        plt.axis('off')
    plt.tight_layout()
    plt.show()

test_predictions([0, 5, 10, 20, 25])

model.save("saved_modelsignature.keras")

"""# Test"""

from keras.models import load_model
model = load_model("saved_modelsignature.keras")

import cv2
import numpy as np
import matplotlib.pyplot as plt


def preprocess_signature(image_path):
    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)
    if img is None:
        raise ValueError(f"Could not read image at {image_path}")

    img = cv2.resize(img, (128, 128))
    _, img = cv2.threshold(img, 127, 255, cv2.THRESH_BINARY_INV)
    img = cv2.GaussianBlur(img, (3, 3), 0)
    img = img / 255.0
    img = img.reshape(1, 128, 128, 1)
    return img


def verify_single_signature(model):
    path = input("Enter path to the signature image: ").strip()

    try:

        img = preprocess_signature(path)
        score = model.predict(img)[0][0]


        result = "GENUINE " if score > 0.5 else "FORGED "
        print(f"\nPrediction Score: {score:.4f} → {result}")


        original_img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)
        plt.imshow(original_img, cmap='gray')
        plt.title(f"Prediction: {result}")
        plt.axis('off')
        plt.show()

    except Exception as e:
        print("Error:", e)

verify_single_signature(model)